{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53699e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [30/Dec/2022 14:57:22] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Dec/2022 14:57:23] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [30/Dec/2022 14:57:55] \"POST /process HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Dec/2022 14:57:55] \"POST /process HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Dec/2022 14:58:52] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import base64\n",
    "import config\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from train import MnistModel\n",
    "import matplotlib.pyplot as plt\n",
    "from flask import Flask, request, render_template, jsonify\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "\n",
    "MODEL = None\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "\n",
    "    def __call__(self, module, module_in, module_out):\n",
    "        self.outputs.append(module_out)\n",
    "\n",
    "    def clear(self):\n",
    "        self.outputs = []\n",
    "\n",
    "\n",
    "def register_hook():\n",
    "    save_output = SaveOutput()\n",
    "    hook_handles = []\n",
    "\n",
    "    for layer in MODEL.modules():\n",
    "        if isinstance(layer, torch.nn.modules.conv.Conv2d):\n",
    "            handle = layer.register_forward_hook(save_output)\n",
    "            hook_handles.append(handle)\n",
    "    return save_output\n",
    "\n",
    "\n",
    "def module_output_to_numpy(tensor):\n",
    "    return tensor.detach().to('cpu').numpy()\n",
    "\n",
    "\n",
    "def autolabel(rects, ax):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{0:.2f}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "def prob_img(probs):\n",
    "    fig, ax = plt.subplots()\n",
    "    rects = ax.bar(range(len(probs)), probs)\n",
    "    ax.set_xticks(range(len(probs)), (0, 1, 2, 3, 4, 5, 6, 7, 8, 9))\n",
    "    ax.set_ylim(0, 110)\n",
    "    ax.set_title('Probability % of Digit by Model')\n",
    "    autolabel(rects, ax)\n",
    "    probimg = BytesIO()\n",
    "    fig.savefig(probimg, format='png')\n",
    "    probencoded = base64.b64encode(probimg.getvalue()).decode('utf-8')\n",
    "    return probencoded\n",
    "\n",
    "\n",
    "def interpretability_img(save_output):\n",
    "    images = module_output_to_numpy(save_output.outputs[0])\n",
    "    with plt.style.context(\"seaborn-white\"):\n",
    "        fig, _ = plt.subplots(figsize=(20, 20))\n",
    "        plt.suptitle(\"Interpretability by Model\", fontsize=50)\n",
    "        for idx in range(16):\n",
    "            plt.subplot(4, 4, idx+1)\n",
    "            plt.imshow(images[0, idx])\n",
    "        plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "    interpretimg = BytesIO()\n",
    "    fig.savefig(interpretimg, format='png')\n",
    "    interpretencoded = base64.b64encode(\n",
    "        interpretimg.getvalue()).decode('utf-8')\n",
    "    return interpretencoded\n",
    "\n",
    "\n",
    "def mnist_prediction(img):\n",
    "    save_output = register_hook()\n",
    "    img = img.to(DEVICE, dtype=torch.float)\n",
    "    outputs = MODEL(x=img)\n",
    "\n",
    "    probs = torch.exp(outputs.data)[0] * 100\n",
    "    probencoded = prob_img(probs)\n",
    "    interpretencoded = interpretability_img(save_output)\n",
    "\n",
    "    _, output = torch.max(outputs.data, 1)\n",
    "    pred = module_output_to_numpy(output)\n",
    "    return pred[0], probencoded, interpretencoded\n",
    "\n",
    "\n",
    "@app.route(\"/process\", methods=[\"GET\", \"POST\"])\n",
    "def process():\n",
    "    data_url = str(request.get_data())\n",
    "    offset = data_url.index(',')+1\n",
    "    img_bytes = base64.b64decode(data_url[offset:])\n",
    "    img = Image.open(BytesIO(img_bytes))\n",
    "    img = img.convert('L')\n",
    "    img = img.resize((28, 28))\n",
    "    # img.save(r'templates\\image.png')\n",
    "    img = np.array(img)\n",
    "    img = img.reshape((1, 28, 28))\n",
    "    img = torch.tensor(img, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "    data, probencoded, interpretencoded = mnist_prediction(img)\n",
    "\n",
    "    response = {\n",
    "        'data': str(data),\n",
    "        'probencoded': str(probencoded),\n",
    "        'interpretencoded': str(interpretencoded),\n",
    "    }\n",
    "    return jsonify(response)\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def start():\n",
    "    return render_template(\"default.html\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    MODEL = MnistModel(classes=10)\n",
    "    MODEL.load_state_dict(torch.load(\n",
    "        'checkpoint/mnist.pt', map_location=DEVICE))\n",
    "    MODEL.to(DEVICE)\n",
    "    MODEL.eval()\n",
    "    app.run(host=config.HOST, port=config.PORT, debug=config.DEBUG_MODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ee95ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
